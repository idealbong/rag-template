import os
import asyncio
from typing import List, Protocol, Optional
from functools import partial
from app.models import DocumentChunk
from sentence_transformers import CrossEncoder
from .void_retrieval_adapter import VoidRetrievalAdapter

from dotenv import load_dotenv
load_dotenv()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Vector store adapters (êµì²´ ê°€ëŠ¥)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class VectorStoreAdapter(Protocol):
    """All adapters must return (Document-like, similarity[0..1]) pairs."""
    def load(self) -> None: ...
    def retrieve(self,
                query: str,
                top_k: int = int(os.getenv("TOP_K", 3)),  # Default to 3 if not set
                source_type: Optional[str] = None,  # Optional filter by source type
                title: Optional[str] = None,  # Optional filter by title keyword
                url: Optional[str] = None  # Optional filter by URL keyword
            ) -> List[DocumentChunk]: ...
    def count(self) -> int: ...


def make_vector_store_adapter() -> VectorStoreAdapter:
    vector_db = os.getenv("VECTOR_DB", "none").lower()
    embedding_model = os.getenv("EMBEDDING_MODEL", "Qwen/Qwen3-Embedding-0.6B")
    if vector_db == "faiss":
        from app.services.faiss_adapter import FaissAdapter
        index_dir = os.getenv("FAISS_INDEX_DIR", "data/faiss_index")
        return FaissAdapter(index_dir=index_dir, embedding_model_name=embedding_model)
    print(f"Unsupported VECTOR_DB: {vector_db}")
    return VoidRetrievalAdapter()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RetrievalService â†’ List[DocumentChunk] ë°˜í™˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class RetrievalService:
    def __init__(self, vector_store: Optional[VectorStoreAdapter] = None):
        self._rerank_enabled = os.getenv("RERANK_ENABLED", "true").lower() == "true"
        self.vector_store = vector_store or make_vector_store_adapter()
        self.cross_encoder_model = os.getenv("CROSS_ENCODER_MODEL", "dragonkue/bge-reranker-v2-m3-ko")
        self.cross_encoder_device = os.getenv("CROSS_ENCODER_DEVICE", "cpu")
        self.cross_encoder = CrossEncoder(self.cross_encoder_model, device=self.cross_encoder_device) if self._rerank_enabled else None
        self._initialize()

    def _initialize(self):
        try:
            print("ðŸ”Œ Loading vector store adapter...")
            self.vector_store.load()
            print(f"âœ… Vector store loaded. count={self.vector_store.count()}")
        except Exception as e:
            print(f"âŒ Error initializing RetrievalService: {e}")
            self.vector_store = VoidRetrievalAdapter()

    async def retrieve(self,
                    query: str,
                    candidate_k: Optional[int] = None,  # Optional rerank candidates
                    top_k: int = int(os.getenv("TOP_K", 3)),  # Default to 3 if not set
                    source_type: Optional[str] = None,  # Optional filter by source type
                    title: Optional[str] = None,  # Optional filter by title keyword
                    url: Optional[str] = None  # Optional filter by URL keyword
                ) -> List[DocumentChunk]:
        """ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•˜ê³ , DocumentChunk ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜."""
        if not self.vector_store:
            return []
        try:
            retrieved_k = candidate_k if (candidate_k and candidate_k > top_k) else top_k

            # 1) ë²¡í„° DBì—ì„œ í›„ë³´ ê²€ìƒ‰ (â˜… í‚¤ì›Œë“œ ì¸ìž)
            chunks = await self._retrieve_vector_db(
                query=query,
                top_k=retrieved_k,
                source_type=source_type,
                title=title,
                url=url,
            )

            # 2) í›„ë³´ê°€ ë” ë§Žìœ¼ë©´ Reranking(cross-encoder ìž¬ì •ë ¬)
            if self._rerank_enabled and self.cross_encoder and (retrieved_k > top_k) and (len(chunks) > top_k):
                pairs = [(query, chunk.chunk_text) for chunk in chunks]
                scores = self.cross_encoder.predict(pairs)
                for chunk, score in zip(chunks, scores):
                    chunk.score = float(round(float(score), 4))
                chunks.sort(key=lambda x: x.score, reverse=True)
                chunks = chunks[:top_k]
                
            if not chunks:
                print("No similar chunks found.")
                return []
            
            return chunks
        except Exception as e:
            raise RuntimeError(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    async def _retrieve_vector_db(self,
                    query: str,
                    top_k: int = int(os.getenv("TOP_K", 3)),  # Default to 3 if not set
                    source_type: Optional[str] = None,  # Optional filter by source type
                    title: Optional[str] = None,  # Optional filter by title keyword
                    url: Optional[str] = None  # Optional filter by URL keyword
                ) -> List[DocumentChunk]:
        """ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•˜ê³ , DocumentChunk ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜."""
        if not self.vector_store:
            return []
        try:
            loop = asyncio.get_running_loop()
            func = partial(
                self.vector_store.retrieve,
                query=query,
                top_k=top_k,
                source_type=source_type,
                title=title,
                url=url,
            )
            chunks = await loop.run_in_executor(None, func)
            if not chunks:
                print("No similar chunks found.")
                return []
            return chunks
        except Exception as e:
            raise RuntimeError(f"Vector DB ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
    def get_index_info(self) -> dict:
        if not self.vector_store._loaded:
            return {"status": "not_loaded", "count": 0}
        try:
            return {
                "status": "loaded",
                "count": self.vector_store.count(),
                "backend": os.getenv("VECTOR_DB", "none"),
                "embedding_model": os.getenv("EMBEDDING_MODEL", "Qwen/Qwen3-Embedding-0.6B"),
                "rerank_enabled": self._rerank_enabled,
                "cross_encoder_model": self.cross_encoder_model if self._rerank_enabled else None,
                "cross_encoder_device": self.cross_encoder_device if self._rerank_enabled else None,
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}
